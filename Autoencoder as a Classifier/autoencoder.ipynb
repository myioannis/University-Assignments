{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "49I5xMy1Rh6d"
      },
      "source": [
        "import sys, os\n",
        "# If this is run on colab, it clones the git repository, so that you don't have to upload the datasets on your google drive\n",
        "if 'google.colab' in sys.modules:\n",
        "  !git clone https://github.com/myioannis/Project-2.git\n",
        "  # Change to the directory of the cloned repository\n",
        "  %cd Project-2\n",
        "  sys.path.append(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHL-Iz4GknTs"
      },
      "source": [
        "from utilities import read_Data, read_Labels, AE_parse_CLA, CL_parse_CLA, AE_read_Hyperparameters, CL_read_Hyperparameters, preprocess #from our utilities.py\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBgTmWGQkofj"
      },
      "source": [
        "# The encoding part of the autoencoder\n",
        "def encoder(input_img, hyperparameters):\n",
        "    # Read the hyperparameters\n",
        "    conv_layers, kernel_size, conv_filters = hyperparameters[:3]\n",
        "    # First convolutional layer (at least one)\n",
        "    conv = Conv2D(conv_filters[0], (kernel_size, kernel_size), activation='relu', padding='same')(input_img)\n",
        "    conv = BatchNormalization()(conv)\n",
        "    if conv.shape[1] % 2 == 0:\n",
        "        # Downsample image by half if possible\n",
        "        conv = MaxPooling2D((2, 2))(conv)\n",
        "        # Dropout to avoid overfitting\n",
        "        conv = Dropout(0.2)(conv)\n",
        "\n",
        "    # Remaining convolutional layers\n",
        "    for i in range(1, conv_layers):\n",
        "        conv = Conv2D(conv_filters[i], (kernel_size, kernel_size), activation='relu', padding='same')(conv)\n",
        "        conv = BatchNormalization()(conv)\n",
        "        if conv.shape[1] % 2 == 0:\n",
        "            conv = MaxPooling2D((2, 2))(conv)\n",
        "            conv = Dropout(0.2)(conv)\n",
        "    return conv\n",
        "\n",
        "# The decoding part of the autoencoder\n",
        "def decoder(conv, hyperparameters):\n",
        "    conv_layers, kernel_size, conv_filters = hyperparameters[:3]\n",
        "    for i in reversed(range(conv_layers)):\n",
        "        conv = Conv2D(conv_filters[i], (kernel_size, kernel_size), activation='relu', padding='same')(conv)\n",
        "        conv = BatchNormalization()(conv)\n",
        "        if i <= 1:\n",
        "            # For 28x28 images, downsampling happens only 2 times (28x28 -> 14x14 -> 7x7)\n",
        "            conv = UpSampling2D((2, 2))(conv)\n",
        "            conv = Dropout(0.2)(conv)\n",
        "    decoded = Conv2D(1, (kernel_size, kernel_size), activation='sigmoid', padding='same')(conv)\n",
        "    return decoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcGvvd4U8yAI"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "  # Parse the command line arguments\n",
        "  trainData_Path = AE_parse_CLA(sys.argv)\n",
        "  # If any of the path arguments was not given (forgotten or running as a jupyter notebook), then ask for them\n",
        "  if not trainData_Path: trainData_Path = input('Please provide the path of the training data: ')  #trainData_Path = \"train-images-idx3-ubyte.gz\"\n",
        "  # Read the datasets\n",
        "  trainData = read_Data(trainData_Path)\n",
        "  # Preprocess the data\n",
        "  trainData = preprocess(trainData)\n",
        "\n",
        "  history = [] # a list of the trained models' loss history and the corresponding hyperparameters of each model\n",
        "  choice = 1\n",
        "  while choice != 0 :\n",
        "    if choice == 1:\n",
        "      # Ask the user for the hyperparameters\n",
        "      hyperparameters = AE_read_Hyperparameters()\n",
        "      epochs, batch_size = hyperparameters[3:]\n",
        "      # Create the model\n",
        "      input_img = Input(shape = (trainData.shape[1], trainData.shape[2], 1))\n",
        "      autoencoder = Model(input_img, decoder(encoder(input_img,hyperparameters),hyperparameters))\n",
        "      autoencoder.compile(loss='mean_squared_error', optimizer = RMSprop(lr=0.001))\n",
        "      # Train the model\n",
        "      autoencoder_train = autoencoder.fit(\n",
        "          trainData, \n",
        "          trainData, \n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_split=0.2,\n",
        "          shuffle=True\n",
        "      )\n",
        "      history.append((autoencoder_train,hyperparameters))\n",
        "    elif choice == 2:\n",
        "      # Plot the loss and validation loss of each model\n",
        "      for model,hyperparams in history:\n",
        "        conv_layers, kernel_size, conv_filters, epochs, batch_size = hyperparams\n",
        "        print(f'Model: Convolutional Layers = {conv_layers}, Kernel Size = {kernel_size}, Convolutional Filters = {conv_filters}, Epochs = {epochs}, Batch Size = {batch_size}')\n",
        "        plt.plot(model.history['loss'])\n",
        "        plt.plot(model.history['val_loss'])\n",
        "        plt.title('Model Loss')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "        plt.show()        \n",
        "    elif choice == 3:\n",
        "      # Save the (whole) model\n",
        "      model_Path = input(\"Where would you like the model to be saved? Provide relative path: \")\n",
        "      autoencoder.save(model_Path)\n",
        "    choice = int(input(\"What would you like to do next?\\n 0) Exit\\n 1) Repeat the experiment with different parameters\\n 2) Plot the loss for each experiment\\n 3) Save the most recent -whole- model\\n\"))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMouJ4wuqv_1"
      },
      "source": [
        "# This deletes the cloned repository from the current colab session. You don't have to run it, since when the session ends, all files are deleted\n",
        "if 'google.colab' in sys.modules:\n",
        "  %cd ..\n",
        "  !rm -rf Project-2"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}